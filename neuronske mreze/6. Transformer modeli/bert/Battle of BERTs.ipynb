{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "093e0691-c9ed-463a-8ab2-95cd8244aedd",
   "metadata": {},
   "source": [
    "# Battle of BERTs\n",
    "\n",
    "Fine-tuning BERT modela za određivanje žanra pesme na osnovu njenog teksta (srpski jezik). Modeli koji će se koristiti:\n",
    "\n",
    "* BERT\n",
    "* Multijezički BERT\n",
    "* BERTić"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2a663f-44bb-4d48-9095-0c3245f6d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4819f761-3f09-43c9-8e09-e8b1cf6ba6d0",
   "metadata": {},
   "source": [
    "## Priprema podataka\n",
    "\n",
    "Učitavamo tekstove pesama i dodeljujemo odgovarajuću labelu svakom tekstu, i nakon toga ih konvertujemo u oblik nepohodan za *transformers* biblioteku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0c8fec-f6c3-4705-92d6-5c5b9593401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path):\n",
    "    data = []\n",
    "    for label, folder_name in enumerate(os.listdir(base_path)):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"Folder: {folder_path} - Label: {label}\")\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                file_path = os.path.join(folder_path, file_name)\n",
    "                if file_name.endswith(\".txt\"):\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        text = file.read().strip()\n",
    "                        data.append({\"text\": text, \"label\": label})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf8f48e-8852-472d-b4b9-1071082b819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(base_path):\n",
    "    data = load_data(base_path)\n",
    "    print(\"\\nTotal data size: \", len(data))\n",
    "\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=1244)\n",
    "    print(\"Train data size: \", len(train_data))\n",
    "    print(\"Test data size: \", len(test_data))\n",
    "\n",
    "    train_dataset = Dataset.from_list(train_data)\n",
    "    test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        \"test\": test_dataset\n",
    "    })\n",
    "\n",
    "    print(\"\\nSample train data:\")\n",
    "    print(dataset[\"train\"][0])\n",
    "    print(\"\\nSample test data:\")\n",
    "    print(dataset[\"test\"][0])\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba52786-b653-47e3-9d39-61b93be91bdf",
   "metadata": {},
   "source": [
    "## Prirema metrika\n",
    "\n",
    "Pripremamo računanje metrika. U ovom slučaju ćemo koristiti tačnost i makro F1 meru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ae18fd-ad4c-4162-a29d-152cce2d3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"macro\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f24a90-4f0b-4186-b3f3-96e60eb66c66",
   "metadata": {},
   "source": [
    "## Tokenizacija, trening i evaluacija\n",
    "\n",
    "Pripremamo generički kod koji će za dati model odraditi:\n",
    "- tokenizaciju koristeći odgovarajući tokenizator za model\n",
    "- treniranje modela\n",
    "- evaluaciju modela koristeći pripremljene metrike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aed5f933-80f7-4987-a7f0-2f17151e7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model_name, dataset):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\").remove_columns([\"text\"])\n",
    "    tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"./results-{model_name}\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        logging_dir=f\"./logs-{model_name}\",\n",
    "        logging_steps=10\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation results for {model_name}: {eval_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0b73ab-b97c-4adc-a70c-759c4e1f9e68",
   "metadata": {},
   "source": [
    "## Primena na modelima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e245304d-56f0-4fa9-a61c-ee2e02b15ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: data/pop - Label: 0\n",
      "Folder: data/rock - Label: 1\n",
      "Folder: data/folk - Label: 2\n",
      "\n",
      "Total data size:  3632\n",
      "Train data size:  2905\n",
      "Test data size:  727\n",
      "\n",
      "Sample train data:\n",
      "{'text': \"Ja osecam da dolazis\\njer kisa odma' prestane\\ni ulice ponesu osmeh\\nkoji dobro znam\\n\\nU kosi nosi upletenu\\nsvetlo znane nestane\\ni prsten sa tri kamena\\nmi ispustas na dlan\\n\\nTi hoces da te zavodim\\na ne znas jezik magije\\nti hoces da te osvojim\\na ne znas da li znam\\n\\nJa hocu da te zagrlim\\ni kazem tajnu najvecu\\ni najlepsu od tajni\\nkoje zelim da ti dam\\n\\nRef.\\nHej, Lolita\\nda l' je to ljubav ili strast\\nhej, Lolita\\nnad mojim srcem imas vlast\\n\\nDok pricas, zriju jabuke\\nrasterujem im oblake\\nispuni mi tri zelje\\ni ispricaj mi san\\n\\nDa ludujem, da zavolim\\ni nikad da ne ostarim\\nizmenjenu istinu\\nmi urezi na dlan\\n\\nTi hoces da te zavodim\\na ne znas jezik magije\\nti hoces da te osvojim\\na ne znas da li znam\\n\\nJa hocu da te zagrlim\\ni kazem tajnu najvecu\\ni najlepsu od tajni\\nkoje zelim da ti dam\\n\\nRef.\", 'label': 1}\n",
      "\n",
      "Sample test data:\n",
      "{'text': 'Kazi mi ko je ta\\nsto te vise od mene voli\\nkazi mi ko je ta\\nsto mi nanosi boli\\n\\nDa ja\\nnisam za tebe zivela\\nne bih te volela\\nja bih prebolela\\n(2x)\\n\\nRef. 2x\\nS njom, idi s njom, pomiricu se s tim\\ntebe da zaboravim\\nja cvrsto zemlju gazicu\\nu snovima tebe mazicu\\n\\nKazi mi gde je bol\\nkada dusa je moja prazna\\nkazi mi ljubavi\\nda li je ovo kazna\\n\\nZa sve\\nsve ove moje godine\\nsto sam te volela\\nsama sam ostala\\n(2x)\\n\\nRef. 3x', 'label': 2}\n"
     ]
    }
   ],
   "source": [
    "dataset = prepare_dataset(\"data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0ef2b-eac8-40b4-a8d1-301efb8b4e90",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7f83d4-1aa0-4e16-ad84-37f8f7bec6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85da1abacff411fbd12fabb0a9cc00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2905 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fda1af7482d46cf8a4523965e78e12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/k3/wn43k8sn2kn36gbj4mmxhqgc0000gn/T/ipykernel_5816/4116740685.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [546/546 04:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.833400</td>\n",
       "      <td>0.845804</td>\n",
       "      <td>0.621733</td>\n",
       "      <td>0.431213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.791197</td>\n",
       "      <td>0.645117</td>\n",
       "      <td>0.423412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.783000</td>\n",
       "      <td>0.786228</td>\n",
       "      <td>0.682256</td>\n",
       "      <td>0.466816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for bert-base-uncased: {'eval_loss': 0.786227822303772, 'eval_accuracy': 0.6822558459422283, 'eval_f1': 0.4668162428540518, 'eval_runtime': 5.3123, 'eval_samples_per_second': 136.852, 'eval_steps_per_second': 8.659, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(\"bert-base-uncased\", dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff03a5a8-b8d1-43bb-92ac-af5325f719b9",
   "metadata": {},
   "source": [
    "### Multijezički BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52bf5079-1755-43fa-8c1c-51e910b3a57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b38c1e01da5460fa1aaa7152be4546b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2905 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2278baf7afa41f080158262dbe97e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/k3/wn43k8sn2kn36gbj4mmxhqgc0000gn/T/ipykernel_5816/4116740685.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [546/546 04:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.753582</td>\n",
       "      <td>0.685007</td>\n",
       "      <td>0.465255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.625400</td>\n",
       "      <td>0.701382</td>\n",
       "      <td>0.713893</td>\n",
       "      <td>0.506263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.616200</td>\n",
       "      <td>0.698616</td>\n",
       "      <td>0.709766</td>\n",
       "      <td>0.518295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for bert-base-multilingual-uncased: {'eval_loss': 0.6986159086227417, 'eval_accuracy': 0.7097661623108665, 'eval_f1': 0.5182949729028036, 'eval_runtime': 5.3393, 'eval_samples_per_second': 136.16, 'eval_steps_per_second': 8.615, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(\"bert-base-multilingual-uncased\", dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64bfbb-ba36-4246-8704-6e0306f2d536",
   "metadata": {},
   "source": [
    "### BERTić"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405195a8-8ebd-445f-98b8-253d6b457e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8164b038a244398b9c0ad22a5515e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2905 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31363f26eea2490a8b8d4efec27c79af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/727 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/k3/wn43k8sn2kn36gbj4mmxhqgc0000gn/T/ipykernel_5816/4116740685.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='546' max='546' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [546/546 04:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.729600</td>\n",
       "      <td>0.741873</td>\n",
       "      <td>0.701513</td>\n",
       "      <td>0.487320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.537100</td>\n",
       "      <td>0.638469</td>\n",
       "      <td>0.733150</td>\n",
       "      <td>0.604311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.467900</td>\n",
       "      <td>0.632898</td>\n",
       "      <td>0.753783</td>\n",
       "      <td>0.631405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a899183989f4d3289b3b50b3f124d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for classla/bcms-bertic: {'eval_loss': 0.6328977942466736, 'eval_accuracy': 0.7537826685006878, 'eval_f1': 0.6314052959447503, 'eval_runtime': 4.7822, 'eval_samples_per_second': 152.023, 'eval_steps_per_second': 9.619, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(\"classla/bcms-bertic\", dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
